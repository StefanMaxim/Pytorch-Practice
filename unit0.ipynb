{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59013d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pytorch Intro:\n",
    "#GPU acceleration: makes code run faster\n",
    "import torch\n",
    "torch.__version__ #used to find the version of the torch your are youring\n",
    "#tensor shape of [3,224,224] is a 3 dimensional tensor to represent images where the dimensions are [color_channels,height,width]\n",
    "#what is a tensor:\n",
    "#area vector: the cross product of the sides, which means that the resulting vector is proportiional to teh area of the vecor and\n",
    "#perpendicular to the surface\n",
    "#vectors are subsets of a tensor class, for which you must understand vector components and basis vectors\n",
    "# the cartesian plane has 3 coordinate basis vectors orthogonal to eachother whose linear combination spans the vector space\n",
    "# these basis vectors have length of one, i hat j hat and k hat all in increasing x,y, and z directions respectively\n",
    "# to find x and y components, just project the vector onto the axis\n",
    "# an n-dim vector can be expressed as a sum of n orthogonal basis vectors  \n",
    "# so vector A = Ax * xhat + Ay * yhat + Az * zhat\n",
    "#where Ax Ay Az are components of a in each direction\n",
    "\n",
    "#here, we need only one index for each of these: A[0], A[1], A[2] because there is only one basis vector per component\n",
    "#making a vector a rank 1 tensor\n",
    "#scalars are rank 0 since they have no directional indicator per component\n",
    "\n",
    "\n",
    "#2D tensor:\n",
    "# Axx Axy Axz\n",
    "# Ayx Ayy Ayz\n",
    "# Azx Azy Azz\n",
    "# xy, as a cross product cannot be expressed as a linear combination of x and y, so they are an entirely different basis vector\n",
    "# Exe: lets suppose you have a 3-D object with axis in the x, y, and z direction. Then, forces can be applied on any of the 3 direction\n",
    "#themselves in different directions. eg in the x direction there are forces in the x,y,and z direction. Thus, you must express the \n",
    "#problem as a 2D tensor as shown above, where you need 2 indexes to access all elements.\n",
    "#NOTE: this is just an interpretation, in reality tensors are more abstract and can represent many different things\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0abca9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: 7 \n",
      " ndim: 0 \n",
      " item 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a 0-dim tensor (scalar)\n",
    "scalar = torch.tensor(data=7) #this way, you can enter in an exact value for the tensor in the parenthesis\n",
    "print(f\"Tensor: {scalar} \\n ndim: {scalar.ndim} \\n item {scalar.item()}\") #this just displays it, but only when it is the last line\n",
    "scalar.ndim #check the dimensions of the tensor object\n",
    "\n",
    "scalar.item() #turns the 0dim tensor into a python integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d844ae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now vectors:\n",
    "#RANK/ORDER: rank is essentially the number of indicies needed to access every element in the tensor\n",
    "#DIMENSIONS: size of the underlying vector space of each index\n",
    "\n",
    "#EXE: a rank 1 tensor in 3 dimensions is like [4,1,6], because it used one index so rank 1, and has 3 values, so the vector\n",
    "#lies in R3 or 3 dimensions\n",
    "\n",
    "\n",
    "\n",
    "vector = torch.tensor(data=[3,2]) #creates a rank 1 tensor with 2 Dimensions\n",
    "vector.ndim #CONFUSING: ndim will return the rank, while shape will return the shape\n",
    "vector.shape #this will return a torch.Size object of [2], which means there are two elements in the first dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f28edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now matrix\n",
    "\n",
    "MATRIX = torch.tensor([[1,2],[3,4]]) #creates a matrix, which has 2 dimensions and size [2,2]\n",
    "MATRIX.ndim # returns 2\n",
    "MATRIX.shape # returns [2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae1d4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensors!\n",
    "\n",
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "TENSOR.ndim #returns 3\n",
    "TENSOR.shape #returns [1,3,3]\n",
    "\n",
    "#NOTE: vectors and scalars use lowercase letters like y or a, and matricies and tensors use uppercase like W or X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0f3b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9094, 0.9527],\n",
       "         [0.0982, 0.1147],\n",
       "         [0.8619, 0.6329]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usually, machine learning starts with large random tensors which are adjusted as it works through the data\n",
    "# process: start with rand numbers > look at data > update rand nums > look at data > update rand ...\n",
    "# Start with random: initialization\n",
    "# Looks at data: representation\n",
    "# Updates random numbers: optimization\n",
    "\n",
    "\n",
    "#for random numbers, use torch.rand(), and pass in a size parameter\n",
    "\n",
    "random_tensor = torch.rand(size=(3,2)) # creates a random tensor of size [3,2], meaning a matrix \n",
    "\n",
    "random_tensor,random_tensor.dtype #this is hwo you print both, and dtype to find the type of data, usually float 32\n",
    "#NOTE: this will output as a tuple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9033d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill a tensor with 0s and ones: use zeros command\n",
    "#NOTE: here, you pass in a parameter with parenthesis like this\n",
    "zero_tensor = torch.zeros(size=(3,2))\n",
    "zero_tensor,zero_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e438c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " torch.float32,\n",
       " 2,\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same thing for ones\n",
    "ones = torch.ones(size=(3,2))\n",
    "ones, ones.dtype, ones.ndim, ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952524c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arange of tensor values\n",
    "#use torch.arange(start, end, step), zero included, 10 not\n",
    "#RETURNS A TENSOR\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ac415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want a zeros or a ones tensor that has the same shape as an existing tensor, use\n",
    "#zeros_like and ones_like, and then imput a torch.tensor object as the param\n",
    "\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb058799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor datatypes:\n",
    "#different types of tensors optimized for GPU and CPU, which are different\n",
    "# default is torch.float32 or torch.float, which is 32 bit floating point number\n",
    "\n",
    "#torch.float16 or torch.half, and torch.float64 or torch.double are other ones\n",
    "#also 8, 16, 32, and 64 bit integers\n",
    "\n",
    "#more bits > more precision > higher accuracy > more compute\n",
    "\n",
    "float_32_tensor = torch.tensor([1,2,3,4], dtype=torch.float32, device=None, requires_grad=False)\n",
    "float_32_tensor.dtype\n",
    "#where dtype is the type of tensor\n",
    "#device defaults to None, which used default tensor type (CPU)\n",
    "#requires_grad if true will record operations done on the tensor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b29e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated tensor is: tensor([[0.9600, 0.4487],\n",
      "        [0.0355, 0.2010],\n",
      "        [0.5507, 0.2576]])\n",
      "Shape of tensor is: torch.Size([3, 2])\n",
      "Datatype of tensor is: torch.float32\n",
      "Device of tensor is: cpu\n"
     ]
    }
   ],
   "source": [
    "# getting attributes from tensors: shape, dtype, and device\n",
    "\n",
    "random_tensor = torch.rand(size=(3,2))\n",
    "print(f\"The generated tensor is: {random_tensor}\")\n",
    "print(f\"Shape of tensor is: {random_tensor.shape}\")\n",
    "print(f\"Datatype of tensor is: {random_tensor.dtype}\")\n",
    "print(f\"Device of tensor is: {random_tensor.device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78e778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor manipulations\n",
    "#adding, substracting, element-wise multiplication, division, matrix multiplication\n",
    "\n",
    "#adding:\n",
    "TENSOR = torch.tensor([1,2,3], dtype=torch.float32, device=None, requires_grad=False)\n",
    "TENSOR = TENSOR + 10 # returns [11,12,13]\n",
    "TENSOR = TENSOR - 10 # returns [1,2,3]\n",
    "TENSOR = TENSOR * 10 #returns 10,20,30\n",
    "TENSOR * 10 # returns 100,200, 300, BUT DOES NOT MODIFY THE NUMBERS INSIDE THE TENSOR!!\n",
    "\n",
    "#can also use torch.mul or torch.add to preform these operations: torch.add(tensor,10) or torch.mul(tensor,10) but less common for\n",
    "#basic operations\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "torch.mul(tensor,tensor) #returns 1,4,9, HERE: each element multiplies its equivalent, so index 0 with index 0, index 1 with 1...\n",
    "#can mutliply any tensors as long as their shapes are broadcastable\n",
    "#Broadcasting: pytorch and numpy can stretch certain vectors across certain dimensions without copying data \n",
    "#WORKS WHEN THE DIMENSIONS ARE EQUAL OR ONE OF THEM IS OF DIM 1\n",
    "# pytorch prepends 1s to the shape of the smaller dim tensor untill they align\n",
    "\n",
    "#exe: multiply a shape A=(2,3) with a B(3)\n",
    "#first, prepend 1 so that (3) becomes (1,3)\n",
    "#then, compare dims:\n",
    "# 2 vs 1, so expand B from (1,3) to (2,3) by copying the number\n",
    "# 3 vs 3, match so works\n",
    "\n",
    "#exe A=[[[1,2],[3,4]]] has shape 1,2,2 and B= [1,2] has shape [2]\n",
    "# B goes to 1,1,2 and so all dimensions are compatible\n",
    "# B becomes [[[1,2],[1,2]]] and then element multiply\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f352e00b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# now matrix multiplication:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#using torch.matmul()\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# here, inner dims must match, resulting shape has outer dims\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# where if size is (5,10,11), the 5 is the 0th dimension, the 10 is the num elements in teh 1st dimension, and the 11 is in the 2nd dim\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     11\u001b[39m A = torch.rand(\u001b[32m3\u001b[39m,\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m B\n",
      "\u001b[31mNameError\u001b[39m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "# now matrix multiplication:\n",
    "#using torch.matmul()\n",
    "# here, inner dims must match, resulting shape has outer dims\n",
    "\n",
    "#Transpose:\n",
    "#can use torch.transpose(imput,dim0,dim1) where imput is the tensor to operate on, and dim0 and dim1 are the dimensions to be swapped\n",
    "# can also use tensor.T where tensor is the tensor to be transposed\n",
    "# where if size is (5,10,11), the 5 is the 0th dimension, the 10 is the num elements in teh 1st dimension, and the 11 is in the 2nd dim\n",
    "#\n",
    "\n",
    "A = torch.rand(3,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#NOTE: UNDERSTAND THE MATH BEHIND TENSOR DOT PRODUCT, TENSOR MATRIX MULTIPLICATION, AND TENSOR TRANSPOSE\n",
    "\n",
    "#Now, normally matrix multiplicaion does not work for non-matricies, but torch.matmul() makes it work using special rules:\n",
    "#NOTE: PROCESS CALLED BATCH MATRIX MULTIPLICATION\n",
    "# A = torch.rand(10,3,2)\n",
    "# B = torch.rand(10,2,3)\n",
    "#pytorch treats this at having to solve 10 matrix multiplications on teh (3,2) with (2,3) matrix, where the multiplications are \n",
    "#done between the matricies of corresponding indicies in the 10, aka torch.matmul(A[0],B[0]), then torch.matmul(A[1],B[1])\n",
    "# and the result will be in the form of shape = (10,3,3)\n",
    "\n",
    "#matrix mutliplication is conducted using broadcasting rules, meaning (10,2,3) can be multiplied by (1,3,2)\n",
    "# and (10,2,3) can be multiplied by (1,1,3) by broadcasting or transposing and broadcasting (IDK WHICH TO GO FOR)\n",
    "\n",
    "#same for (10,10,3,2) matmul (10,10,2,2), you are doing batched matrix multiplication on the batched dimensions, and then normal\n",
    "#matmul on the other ones\n",
    "\n",
    "#DOT PRODUCT:\n",
    "#NICKNAME FOR MATRIX MULTIPLICATION, NOT THE ELEMENT-WISE MULTIPLICATION\n",
    "\n",
    "#TRANSPOSE\n",
    "# .T is for 2d matricies only, transpose is for swapping 2 dimensions only,and permute(neworder=(2,0,1)) is for swapping everything\n",
    "# remember, a transpose doesnt actually change the tensor, just the way its strides are interpreted\n",
    "#exe: for [[[1,2],[3,4]],[[5,6],[7,8]]] , which is size 2,2,2\n",
    "#this tensor has 2 slices, or elements in its outer dimension\n",
    "# each slice has 2\n",
    "\n",
    "\n",
    "#what it does it that it maps the coordinates of each point in the tensor to its transposed location\n",
    "# lets suppose that there is element b located at A[1][3][4], where 1 is the num elements in the 1st dimension, 3 is num in second\n",
    "#dimension, and 4 is elements in 3rd dimension, if you do torch.transpose(tensor,1,0) it will swap the 1 and 0 dimensions, which'\n",
    "#means is will swap 1 and 3\n",
    "\n",
    "#thus, the new location of b, which was A[1][3][4] is now A[3][1][4], and the same will happen for all other elements in the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is tensor([[0.2666, 0.6274],\n",
      "        [0.2696, 0.4414],\n",
      "        [0.2969, 0.8317]]) with dimensions torch.Size([3, 2])\n",
      "Output is tensor([[ 1.0348,  0.4592,  0.3892,  0.0690,  0.3858,  0.3514],\n",
      "        [ 0.9272,  0.3378,  0.3622, -0.0094,  0.4842,  0.3286],\n",
      "        [ 1.1711,  0.5868,  0.4136,  0.1433,  0.2987,  0.3971]],\n",
      "       grad_fn=<AddmmBackward0>) with dimensions torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "#Linear Layer\n",
    "# Formual for a linear layer: y = xW^T +b\n",
    "#where X is the imput to the layer, usually of size (batch_size, in_features)\n",
    "# W or A is the weights matrix, initially randomized of size (out_features, in_features)\n",
    "# T is to transpose it\n",
    "# b is the bias, of size (out_features) (will be broadcast to (batch_size, out_features) when adding)\n",
    "# y is the output, of size (batch_size, out_features), a manipulation of the imput in hopes to discover a pattern in it\n",
    "\n",
    "torch.manual_seed(42) #set a manual seed so that the randomization of the weights is consistant\n",
    "linear = torch.nn.Linear(in_features=2,out_features=6)\n",
    "x = torch.rand(3,2)\n",
    "print(f\"Input is {x} with dimensions {x.shape}\")\n",
    "result = linear(x)\n",
    "print(f\"Output is {result} with dimensions {result.shape}\")\n",
    "\n",
    "\n",
    "# the weights array is size (out_features, in_features), meaning it has out_features arrays of in_feature elements.\n",
    "# each row in this matrix is the weight vector for one neuron (so if a linear layer has 6 out_features it has 6 neurons)\n",
    "# so if a lin layer has 3 in_features and 6 out features, it will have 6 neurons each with a weights vector of size 3\n",
    "\n",
    "# the weights array for each neuron is of size 3 because it will recieve imput from 3 neurons in the form of an array\n",
    "# that is itself size 3\n",
    "# this way, it is multiplying a size 3 array by anouther size 3 array transposed, resulting in a scalar plus bias in a \n",
    "#normalizing function.\n",
    "\n",
    "\n",
    "\n",
    "#DRAW A DIAGRAM IT MAKES SENSE!! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19100f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value = 0\n",
      "Maximum value = 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n",
      "The max is at index 9\n"
     ]
    }
   ],
   "source": [
    "#Now, we move on to aggregation techniques, or how to make a tensor go from many values to fewer (INCLUDES TYPE CHANGES)\n",
    "\n",
    "x = torch.arange(0,100,10)\n",
    "\n",
    "print(f\"Maximum value = {x.min()}\")\n",
    "print(f\"Maximum value = {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") #MUST BE A FLOAT TO FIND THE MEAN, SO TYPECAST\n",
    "print(f\"Sum: {x.sum()}\")\n",
    "\n",
    "#CAN DO THE SAME WITH TORCH METODS LIKE torch.max or torch.min\n",
    "\n",
    "#POSITIONAL MIN/MAX\n",
    "\n",
    "#use torch.argmax() or torch.argmin() to find the index of where the max or min is, or tensor.argmax() and tensor.argmin()\n",
    "\n",
    "print(f\"The max is at index {torch.argmax(x)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0931, 0.9193],\n",
      "        [0.2999, 0.6325],\n",
      "        [0.3265, 0.5406]])\n",
      "tensor([[0.9662, 0.7304],\n",
      "        [0.0667, 0.6985],\n",
      "        [0.9746, 0.6315]])\n",
      "tensor([[[0.0931, 0.9193],\n",
      "         [0.9662, 0.7304]],\n",
      "\n",
      "        [[0.2999, 0.6325],\n",
      "         [0.0667, 0.6985]],\n",
      "\n",
      "        [[0.3265, 0.5406],\n",
      "         [0.9746, 0.6315]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE, the only methods that actually modify the origional tensor are the inplace methods ending in _, the rest return a new one\n",
    "#reshapes, stacking, squeezing, and stretching\n",
    "\n",
    "tensor = torch.rand(size=(3,2))\n",
    "print(tensor)\n",
    "\n",
    "new = torch.reshape(input=tensor,shape=(1,3,2)) #reshapes as in broadcasts only with valid broadcasts \n",
    "#RESHAPE COPIES THE DATA AND RETURNS A NEW TENSOR WITH THAT DATA IN IT\n",
    "#NOTE: DOES NOT MODIFY THE ORIGIONAL TENSOR\n",
    "\n",
    "new.view(size=(3,2)) # here, you can view a tensor as a new size without changing it\n",
    "#NOTE: all this does is return a new tensor with the same memory data (meaning editing the view edits the tensor)\n",
    "#DOES NOT COPY DATA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tensor2 = torch.rand(size=(3,2))\n",
    "print(tensor2)\n",
    "\n",
    "concat = torch.stack((tensor,tensor2),dim=1) # adds a new dimension at dim 0 (the furthest)\n",
    "print(concat)\n",
    "# exe: t1 = [1,2], t2 = [3,4], t3 = [5,6]\n",
    "# each of these tensors have shape [2]\n",
    "# thus, when you add them with dim=0, the resulting shape will be of size [3,2], since 3 is at position of dim 0\n",
    "# if you were to add at dim 1, the resulting shape is [2,3]. REMEMBER: TENSORS ARE ABSTRACT, SO THE WAY THIS WORKS IS LIKE THIS:\n",
    "# t1 = [a,b] where a is an index 0 in dim 0, and b is an index 1 in dim 0\n",
    "# when you stack it, you stack on dim 1, so a now is \n",
    "\n",
    "#NOTE:\n",
    "#Mental Trick: try to think of each dimension as a label, like (2,3,2) could be (channels, width, height)\n",
    "# a permutation just changes the way the data is ordered, like first its the set of all channels, so 3 objects, then all widths,\n",
    "# then all heights\n",
    "# so if you have a tensor to store image data (channels, height, width) of size (3,255,255), and you permute it to \n",
    "# (height, channels, width) its just first a set of all the heights to index, then channels with 3 objects, then widths.\n",
    "# same thing for stacking, which really is just creating a dimension. When you have two objects of size [2] can you stack them on\n",
    "# the first dimension, you create a tensor of class [2,2], where  first you index by the first index in the tensor, and the \n",
    "# by which tensor it is, so T[0][0] means let me get the 0th index of the first tensor\n",
    "\n",
    "\n",
    "\n",
    "#NOW, FOR squeeze, unsqueeze and permute\n",
    "#this will make the tensor of size [2], removing all one element dimensions (rank 1 size [2])\n",
    "testor = torch.rand(size=(1,2,1))\n",
    "t2 = torch.squeeze(testor)\n",
    "\n",
    "#this will add a dimension where you want it to be of size 1, in accordance with broadcasting rules\n",
    "t2 = torch.unsqueeze(input=testor,dim=3)\n",
    "t2.shape # shape is now 1,2,1,1\n",
    "\n",
    "#permute is just like a transpose, but for all dimensions of the tensor\n",
    "t2 = torch.permute(input=testor,dims=(1,0,2))\n",
    "t2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first bracket is the outer dimension (dim 0): tensor([[1, 2, 3]])\n",
      "the second bracket is the middle dimension (dim 1): tensor([1, 2, 3])\n",
      "The last bracket is the outer dimension (dim 2): 1\n"
     ]
    }
   ],
   "source": [
    "#indexing tensors\n",
    "\n",
    "#NOTE: SUPER IMPORTANT!!! reshape and broadcast are not the same things! reshape only cares that the number of elements stays the\n",
    "#same. for view, it must have the same number of sides, but also must be contiguous in memory. THus, you will need to call \n",
    "#tensor.contiguous for it to work. NOW, reshape will attempt to call view, but will end up copying the memory if the data is not\n",
    "#contiguous in memory, so its like a more advanced copy\n",
    "\n",
    "\n",
    "#MECHANICS OF TENSORS DEEP DOWN:\n",
    "# if you write x = torch.rand(size=(8,15,17))\n",
    "# while the object x is a tensor, the memory is stored just as a contiguous array of size 8*15*17 elements\n",
    "# thats 2040 elements layed out in row-major style (c-style)\n",
    "# Row major order just means that rows are placed after eachother \n",
    "# so x[i][j][k] is matter to memory index i*(15*17) + j*(17) + k\n",
    "# pytorch tensors contain metadata with shape (8,15,17) and strides (255,17,1) wich is how much to offset by each index ijk\n",
    "# a tensor reshape or view is just a change to the shape and stride math of the object. The memory remains unchanged\n",
    "#PROVE IT ON PAPER\n",
    "\n",
    "# to store tensor shape (2,2,3), the last dimension (index 2 here) changes the fastest, so it is [0][0][0], [0][0][1], ..\n",
    "# the strides are (6,3,1). \n",
    "\n",
    "\n",
    "#transposes and reshapes are different, with transposes usually making the data non contiguous because the memory layout\n",
    "#no longer matches the row-major order of the new shape\n",
    "# Transpose is the more mathematical one, with the axis actually swapping, reshape is just a way of visualizing the data differently\n",
    "\n",
    "\n",
    "# BASICALLY, if you have an origional tensor x of size (3,6,8) and you say a = x.reshape(8,6,3),\n",
    "# and b = x.permute(2,1,0), the results will be different even if they have the same size\n",
    "\n",
    "#THAT BEING SAID, PERMUTE DOES NOT NECESSARILY HAVE TO CHANGE THE MEMORY, IT CAN STILL GET BY ON JUST CHANGING THE STRIDE\n",
    "# AND SHAPE. SUPER IMPORTANT: CONTIGUOUS DOES NOT MEAN THAT THERE ARE BREAKS IN THE MEMORY, IT JUST MEANS THAT FOR A TENSOR\n",
    "# THAT IS IT STORED IN THE ROW MAJOR ORDER IMPLIED BY ITS SHAPE AND STRIDE. IN OTHER WORDS, IF YOU LOOP THROUGH\n",
    "#ALL THE ELEMENTS IN THE SHAPE IN ORDER, WITH THE LAST DIMENSION CHANGING THE FASTEST, THE PIECES SHOULD REMAIN IN ORDER\n",
    "# AND YOU SHOULDN't BE JUMPING AROUND, WHICH OF COURSE ISN'T TRUE FOR A TRANSPOSE\n",
    "\n",
    "# THUS, RESHAPE WILL RETURN A VIEW IF THE TENSOR IS STILL CONTIGUOUS, BUT IF NOT WILL HAVE TO COPY AND MAKE IT CONTIGUOUS\n",
    "\n",
    "#NOTE:\n",
    "#WHY DOES BEING CONTIGUOUS MATTER?\n",
    "#to reshape without copying, pytorch must be able to simply re-interpret the data, which is only possible when it is in row\n",
    "#major order!! REASON BEING, if you have a tensor of size (3,4) and reshape it to be size (2,6), the 7th element of the \n",
    "#first tensor is the seventh element of the second tensor. The only thing that changed is how you group it\n",
    "\n",
    "#DURING A TRANSPOSE HOWEVER, the data is no longer contiguous, so the seventh element of the origional tensor is not\n",
    "#the seventh of the final tensor, so \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = torch.arange(start=1,end=10,step=1)\n",
    "x = x.reshape(shape=(3,1,3))\n",
    "x,x.shape\n",
    "\n",
    "\n",
    "#now for the actual indexing:\n",
    "\n",
    "print(f\"The first bracket is the outer dimension (dim 0): {x[0]}\")\n",
    "print(f\"the second bracket is the middle dimension (dim 1): {x[0][0]}\")\n",
    "print(f\"The last bracket is the outer dimension (dim 2): {x[0][0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647d2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]]) torch.Size([3, 4])\n",
      "tensor([[ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11],\n",
      "        [ 4,  8, 12]]) torch.Size([4, 3])\n",
      "tensor([[ 1,  5,  9,  2],\n",
      "        [ 6, 10,  3,  7],\n",
      "        [11,  4,  8, 12]]) torch.Size([3, 4])\n",
      "The 7th element of tensor 2 is 8\n",
      "The 7th element of tensor 3 is 10\n"
     ]
    }
   ],
   "source": [
    "#QUESTION: if you apply a reshape on a transposed tensor, does the tensor need to change the way it is?\n",
    "\n",
    "tensor1 = torch.arange(start=1,end=13,step=1)\n",
    "tensor2 = tensor1.reshape(shape=(3,4))\n",
    "print(tensor2,tensor2.shape)\n",
    "tensor3 = tensor2.transpose(0,1)\n",
    "print(tensor3,tensor3.shape)\n",
    "tensor4 = tensor3.reshape(shape=(3,4))\n",
    "print(tensor4, tensor4.shape)  #so after transposing and then resizing to the origional and then indexing it is not the same\n",
    "\n",
    "#WHY DOES IT MATTER?:\n",
    "# given tensor [[1,2,3,4],[5,6,7,8],[8,10,11,12]]\n",
    "# here, the memory is contiguous 1...12\n",
    "# if you transpose it, it will become [[1,5,9],[2,6,10],[3,7,11],[4,8,12]]\n",
    "# but the memory is still 1...12 but now non-contiguous\n",
    "# now, if you do a reshape now, lets say to (4,3), it will want to turn the tensor into [[1,5,9,2],[6,10,3,7],[11,4,8,12]]\n",
    "# But that is not possible by only changing shape and stride since the memory is still 1...12\n",
    "# Thus, you have to copy the memory and make it contiguous, and then you can do the shape and stride trick\n",
    "# since if you just change the shape to (4,3) and the stride to (3,1), the resulting reshape will return\n",
    "# [[1,2,3],[4,5,6],[7,8,9],[10,11,12]], which is not what you want\n",
    "\n",
    "\n",
    "#now check:\n",
    "print(f\"The 7th element of tensor 2 is {tensor2[1][3]}\")\n",
    "print(f\"The 7th element of tensor 3 is {tensor2[2][1]}\")\n",
    "#notice they are not the same, so the order is fundamentally differnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91648479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor as a whole is: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Basically, [:,0] returns: \n",
      "tensor([1, 4, 7]) \n"
     ]
    }
   ],
   "source": [
    "#Indexing but actually\n",
    "\n",
    "tensor = torch.arange(start=1,end=10,step=1).reshape(shape=(3,3))\n",
    "#you can also use :'s to mean all columns at that level, so [:,0] means all elements in the first dim with second dim index 0\n",
    "print(f\"The tensor as a whole is: \\n{tensor}\")\n",
    "print(f\"Basically, [:,0] returns: \\n{tensor[:,0]} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293a528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pytorch and Numpy\n",
    "#two methods to use are torch.from_numpy(numpy)\n",
    "# and torch.Tensor.numpy(tensor)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(start=1.0,stop=10.0,step=1.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array,tensor,tensor.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615955a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5989, 0.1208, 0.0331, 0.5088],\n",
      "        [0.9559, 0.7885, 0.2089, 0.4351],\n",
      "        [0.1314, 0.2588, 0.5905, 0.7723]])\n",
      " tensor([[0.9142, 0.0409, 0.8343, 0.1474],\n",
      "        [0.6872, 0.9231, 0.5070, 0.9549],\n",
      "        [0.0740, 0.3090, 0.7916, 0.3911]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomness\n",
    "\n",
    "rand_tensor1 = torch.rand(size=(3,4))\n",
    "rand_tensor2 = torch.rand(size=(3,4))\n",
    "print(f\"{rand_tensor1}\\n {rand_tensor2}\")\n",
    "#are they equal anywhere\n",
    "rand_tensor1 == rand_tensor2 #compares element wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856d734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8823, 0.9150],\n",
       "         [0.3829, 0.9593],\n",
       "         [0.3904, 0.6009]]),\n",
       " tensor([[0.8823, 0.9150],\n",
       "         [0.3829, 0.9593],\n",
       "         [0.3904, 0.6009]]),\n",
       " tensor([[True, True],\n",
       "         [True, True],\n",
       "         [True, True]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now for the Reproducable randomness\n",
    "\n",
    "import torch\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_tensor1 = torch.rand(size=(3,2))\n",
    "#NOTE: you gotta reset the seed everytime a new rand is called\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_tensor2 = torch.rand(size=(3,2))\n",
    "rand_tensor1,rand_tensor2,rand_tensor1 == rand_tensor2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "mps\n",
      "current tensor is: tensor([1, 2, 3]) on device cpu\n",
      "new tensor is still tensor([1, 2, 3], device='mps:0') on device mps:0\n"
     ]
    }
   ],
   "source": [
    "#TENSORS ON GPUs\n",
    "#generally nvidia gpus with cuda\n",
    "#ways to access GPU: google colab, your own, or cloud computing\n",
    "#to check if you have access to nvidia GPU, run !nvidia-smi ! IS BANG, AND #! IS SHEBANG\n",
    "!nvidia-smi\n",
    "# use torch.cuda package for to get torch working\n",
    "torch.cuda.is_available()\n",
    "\n",
    "#to make a condition cuda not available to run on cpu\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #best practice to run device agnostic code\n",
    "device\n",
    "\n",
    "#to cound the number of gpus you have available\n",
    "torch.cuda.device_count()\n",
    "\n",
    "\n",
    "#for running on mac:\n",
    "torch.backends.mps.is_available() #this is like the torch.cuda.is_available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "#for the ultimate agnostic case, use an if statment\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" #uses nvidia drivers if available\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)\n",
    "# Make me a tic tac toe solver\n",
    "\n",
    "\n",
    "\n",
    "#to move tensors from cpu to gpu, use torch.Tensor.to(device)\n",
    "\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(f\"current tensor is: {tensor} on device {tensor.device}\")\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(f\"new tensor is still {tensor_on_gpu} on device {tensor_on_gpu.device}\") #mps:0 means it stores it on the 0th gpu index\n",
    "#if you have multiple gpus\n",
    "\n",
    "#moving tensors back to cpu\n",
    "# if you use the old method of torch.tensor.numpy() it will error because the tensor is not stored in memory\n",
    "#thus, you must use the torch.tensor.cpu()\n",
    "\n",
    "\n",
    "#!nvidia-smi\n",
    "# torch.cuda.is_available\n",
    "# device = \"cuda\"\n",
    "# torch.cuda.device_count()\n",
    "# for multiple GPUs, use DDP, or distributed data parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba415d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
      "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
      "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
      "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
      "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]]) torch.Size([7, 1])\n"
     ]
    }
   ],
   "source": [
    "#HW:\n",
    "\n",
    "#random tensor with shape (7,7)\n",
    "\n",
    "import torch\n",
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_tensor = torch.rand(size=(7,7))\n",
    "print(rand_tensor)\n",
    "#torch.manual_seed(seed=RANDOM_SEED)\n",
    "rand_tensor2 = torch.rand(size=(1,7))\n",
    "prod_tensor = torch.matmul(rand_tensor,rand_tensor2.transpose(dim0=0,dim1=1))  #.T or .transpose(dim0=0,dim1=1)\n",
    "print(prod_tensor,prod_tensor.shape)\n",
    "\n",
    "\n",
    "#NOTE, only reset the random seed if you want the random numbers created to be exactly the same\n",
    "#usually, just one random seed will suffice since after that all the random numbers generated are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35049d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Min value is 0.3647301495075226\n",
      "Max value is 0.5617256760597229\n",
      "Min value index is 0\n",
      "Max value index is 3\n"
     ]
    }
   ],
   "source": [
    "#HW cont\n",
    "#torch.manual_seed(seed= is for CPUs! how to do it for GPUs?)\n",
    "\n",
    "#set_rng_state_all sets the rng state for all gpus to the same number. can also use torch.cuda.manual_seed_all\n",
    "\n",
    "RANDOM_SEED = 1234\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "t1 = torch.rand(size=(2,3))\n",
    "t2 = torch.rand(size=(2,3))\n",
    "t1_on_gpu = t1.to(device)\n",
    "t2_on_gpu = t2.to(device)\n",
    "device,t1_on_gpu, t2_on_gpu, \n",
    "\n",
    "prod = torch.matmul(t1_on_gpu, t2_on_gpu.T)\n",
    "prod, prod.shape\n",
    "\n",
    "print(f\"Min value is {prod.min()}\")\n",
    "print(f\"Max value is {prod.max()}\")\n",
    "print(f\"Min value index is {prod.argmin()}\")\n",
    "print(f\"Max value index is {prod.argmax()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b59a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origional tensor is (tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]), torch.Size([1, 1, 1, 10]))\n",
      "The squeezed tensor is (tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]), torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "RANDOM_SEED = 7\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "tensor = torch.rand(size=(1,1,1,10))\n",
    "print(f\"The origional tensor is {tensor, tensor.shape}\")\n",
    "t_squeeze = tensor.squeeze()\n",
    "print(f\"The squeezed tensor is {t_squeeze,t_squeeze.shape}\")\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
